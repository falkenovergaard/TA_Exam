{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Authors: Clay Woolam <clay@woolam.org>\n",
    "# License: BSD\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.semi_supervised import label_propagation\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "974\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"data/clean_labeled_data.xlsx\")\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "rng = np.random.RandomState(2)\n",
    "indices = np.arange(len(df))\n",
    "rng.shuffle(indices)\n",
    "\n",
    "corpus = df.COMMENT.astype(str)\n",
    "y = df['LABEL'].values.astype(int)\n",
    " \n",
    "vectorizer = CountVectorizer(input='content',binary=False,ngram_range=(1,1))\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "count = vectorizer.fit_transform(corpus).toarray()\n",
    "X = transformer.fit_transform(count).toarray()\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = X[indices[:800]]\n",
    "y = y[indices[:800]]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_total_samples = len(y)\n",
    "\n",
    "n_labeled_points = 173\n",
    "\n",
    "indices = np.arange(n_total_samples)\n",
    "\n",
    "\n",
    "unlabeled_set = indices[n_labeled_points:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  1  1  0  2  0  2  2  2  1  0  2  2  1  2  1  0  0  2  1  2  2  0  2\n",
      "  2  0  0  0  0  2  2  2  2  0  1  0  1  0  0  0  1  1  1  1  1  2  2  2\n",
      "  1  2  1  0  2  0  0  1  0  2  1  2  1  2  0  0  1  1  0  0  0  2  2  2\n",
      "  0  2  1  0  0  1  0  1  2  2  2  2  1  0  0  0  2  0  0  0  0  0  1  2\n",
      "  2  2  1  0  1  0  0  1  2  1  0  0  2  0  2  0  2  0  2  0  1  1  2  0\n",
      "  0  0  0  2  2  1  0  2  1  2  1  2  2  2  2  0  0  2  1  1  2  2  0  0\n",
      "  1  2  1  0  0  0  0  0  0  2  2  2  0  0  2  1  2  0  2  0  1  0  0  2\n",
      "  1  1  0  2  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "# #############################################################################\n",
    "# Shuffle everything around\n",
    "y_train = np.copy(y)\n",
    "y_train[unlabeled_set] = -1\n",
    "print(y_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[2 0 2 0 2 0 0 1 1 0 2 2 1 0 1 0 2 2 0 0 2 0 1 2 0 1 2 0 1 0 1 1 1 1 1 2 2\n",
      " 0 2 0 2 2 2 0 2 2 2 0 0 0 2 0 2 1 0 1 0 2 1 0 2 0 1 2 0 0 2 1 2 2 0 1 0 0\n",
      " 2 0 0 0 2 2 2 0 1 0 2 0 2 0 0 0 0 0 2 0 2 2 2 2 0 2 2 2 1 0 0 0 2 0 0 1 1\n",
      " 2 0 2 2 2 2 1 0 1 2 1 0 2 0 1 0 1 1 2 1 0 2 2 2 2 0 1 0 0 0 0 2 2 0 1 2 2\n",
      " 2 0 0 2 0 2 1 1 0 0 0 0 2 0 0 0 0 2 2 1 2 0 1 0 1 0 2 1 2 1 1 0 2 2 1 0 1\n",
      " 1 0 2 2 1 0 1 2 0 1 2 1 2 1 0 1 1 1 0 1 1 0 1 2 0 1 0 1 0 0 2 2 1 0 0 0 0\n",
      " 2 1 2 0 0 2 2 2 1 2 1 2 0 0 2 2 2 2 0 0 0 0 1 1 0 0 1 0 1 0 2 2 1 0 0 1 2\n",
      " 1 0 1 2 0 2 0 1 0 0 0 1 0 2 2 1 2 2 1 2 1 2 2 2 1 0 2 1 1 1 0 0 0 0 0 2 2\n",
      " 2 0 0 1 0 1 2 0 2 0 0 1 0 0 1 1 1 2 2 0 1 0 0 1 1 2 1 0 2 2 2 2 0 0 0 1 2\n",
      " 0 2 1 1 0 2 1 2 1 0 1 0 2 1 0 2 2 0 0 2 0 0 1 1 2 2 1 2 0 1 0 0 0 2 0 2 1\n",
      " 1 0 2 0 0 2 0 0 0 1 1 0 0 1 2 0 0 2 0 1 1 0 0 0 0 0 1 2 2 1 2 0 2 2 0 2 0\n",
      " 1 2 2 1 0 1 0 1 0 0 2 2 0 2 0 2 0 1 0 1 2 2 2 0 1 2 0 1 0 2 1 2 0 0 1 2 2\n",
      " 1 0 1 1 0 2 2 1 0 0 0 0 0 2 2 0 2 1 2 1 2 0 1 2 0 0 1 0 1 2 2 0 2 0 0 0 1\n",
      " 1 2 1 0 1 2 2 2 1 0 0 1 1 0 2 2 0 2 1 0 0 1 0 1 0 0 2 1 1 2 1 1 0 2 0 0 0\n",
      " 0 1 0 2 2 0 2 2 2 1 2 0 2 2 2 0 0 0 2 2 0 0 2 1 0 1 0 1 0 0 2 2 2 2 1 0 2\n",
      " 2 1 1 0 2 1 2 0 1 1 2 0 2 0 0 1 0 2 0 2 2 2 2 0 0 1 2 0 1 0 0 0 1 0 1 2 0\n",
      " 1 1 1 1 0 0 2 0 1 1 0 0 0 2 2 1 2 2 1 2 2 2 1 2 2 0 2 2 0 0 1 1 0 1 1]\n",
      "Label Spreading model: 173 labeled & 627 unlabeled points (800 total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      1.00      0.56       246\n",
      "           1       0.00      0.00      0.00       168\n",
      "           2       0.00      0.00      0.00       213\n",
      "\n",
      "   micro avg       0.39      0.39      0.39       627\n",
      "   macro avg       0.13      0.33      0.19       627\n",
      "weighted avg       0.15      0.39      0.22       627\n",
      "\n",
      "Confusion matrix\n",
      "[[246   0   0]\n",
      " [168   0   0]\n",
      " [213   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morten/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# #############################################################################\n",
    "# Learn with LabelSpreading\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "lp_model = label_propagation.LabelSpreading(gamma=.25, max_iter=20)\n",
    "\n",
    "lp_model.fit(X, y_train)\n",
    "\n",
    "predicted_labels = lp_model.transduction_[unlabeled_set]\n",
    "print(predicted_labels)\n",
    "true_labels = y[unlabeled_set]\n",
    "print(true_labels)\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_labels, labels=lp_model.classes_)\n",
    "\n",
    "print(\"Label Spreading model: %d labeled & %d unlabeled points (%d total)\" %\n",
    "      (n_labeled_points, n_total_samples - n_labeled_points, n_total_samples))\n",
    "\n",
    "print(classification_report(true_labels, predicted_labels))\n",
    "\n",
    "print(\"Confusion matrix\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Label Spreading model: 40 labeled & 300 unlabeled points (340 total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        27\n",
      "           1       0.82      1.00      0.90        37\n",
      "           2       1.00      0.86      0.92        28\n",
      "           3       1.00      0.80      0.89        35\n",
      "           4       0.92      1.00      0.96        24\n",
      "           5       0.74      0.94      0.83        34\n",
      "           6       0.89      0.96      0.92        25\n",
      "           7       0.94      0.89      0.91        35\n",
      "           8       1.00      0.68      0.81        31\n",
      "           9       0.81      0.88      0.84        24\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       300\n",
      "   macro avg       0.91      0.90      0.90       300\n",
      "weighted avg       0.91      0.90      0.90       300\n",
      "\n",
      "Confusion matrix\n",
      "[[27  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 37  0  0  0  0  0  0  0  0]\n",
      " [ 0  1 24  0  0  0  2  1  0  0]\n",
      " [ 0  0  0 28  0  5  0  1  0  1]\n",
      " [ 0  0  0  0 24  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 32  0  0  0  2]\n",
      " [ 0  0  0  0  0  1 24  0  0  0]\n",
      " [ 0  0  0  0  1  3  0 31  0  0]\n",
      " [ 0  7  0  0  0  0  1  0 21  2]\n",
      " [ 0  0  0  0  1  2  0  0  0 21]]\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "rng = np.random.RandomState(2)\n",
    "indices = np.arange(len(digits.data))\n",
    "rng.shuffle(indices)\n",
    "\n",
    "X = digits.data[indices[:340]]\n",
    "y = digits.target[indices[:340]]\n",
    "\n",
    "n_total_samples = len(y)\n",
    "n_labeled_points = 40\n",
    "\n",
    "indices = np.arange(n_total_samples)\n",
    "\n",
    "unlabeled_set = indices[n_labeled_points:]\n",
    "\n",
    "# #############################################################################\n",
    "# Shuffle everything around\n",
    "y_train = np.copy(y)\n",
    "y_train[unlabeled_set] = -1\n",
    "\n",
    "# #############################################################################\n",
    "# Learn with LabelSpreading\n",
    "lp_model = label_propagation.LabelSpreading(gamma=.25, max_iter=20)\n",
    "lp_model.fit(X, y_train)\n",
    "predicted_labels = lp_model.transduction_[unlabeled_set]\n",
    "true_labels = y[unlabeled_set]\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_labels, labels=lp_model.classes_)\n",
    "\n",
    "print(\"Label Spreading model: %d labeled & %d unlabeled points (%d total)\" %\n",
    "      (n_labeled_points, n_total_samples - n_labeled_points, n_total_samples))\n",
    "\n",
    "print(classification_report(true_labels, predicted_labels))\n",
    "\n",
    "print(\"Confusion matrix\")\n",
    "print(cm)\n",
    "\n",
    "# #############################################################################\n",
    "# Calculate uncertainty values for each transduced distribution\n",
    "pred_entropies = stats.distributions.entropy(lp_model.label_distributions_.T)\n",
    "\n",
    "# #############################################################################\n",
    "# Pick the top 10 most uncertain labels\n",
    "uncertainty_index = np.argsort(pred_entropies)[-10:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
