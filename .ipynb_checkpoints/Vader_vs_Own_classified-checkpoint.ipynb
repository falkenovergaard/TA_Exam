{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = pd.read_excel('data/output/clean_handlabeled_data.xlsx')\n",
    "df_neg = pd.read_excel('data/output/clean_handlabeled_data.xlsx')\n",
    "df_pos_vader = pd.read_excel('data/output/clean_handlabeled_data.xlsx')\n",
    "df_neg_vader = pd.read_excel('data/output/clean_handlabeled_data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_null_and_mapping(df, map_to, df_type):\n",
    "    \n",
    "    if df_type == 'vader':\n",
    "        df = df[pd.notnull(df['COMMENT'])]\n",
    "        df = df[pd.notnull(df['LABEL'])]\n",
    "        return df\n",
    "\n",
    "    elif df_type == 'hl':\n",
    "    \n",
    "        if map_to == 'POS':\n",
    "            df['LABEL'] = df['LABEL'].map({'NEU':'POS','POS':'POS','NEG':'NEG'})\n",
    "        elif map_to == 'NEG':\n",
    "            df['LABEL'] = df['LABEL'].map({'NEU':'NEG','POS':'POS','NEG':'NEG'})\n",
    "            \n",
    "        df['TRUE_LABEL'] = df['LABEL'].map({'POS':int(1),'NEG':int(0)})\n",
    "        df['TRUE_LABEL'] = df['LABEL'].map({'POS':int(1),'NEG':int(0)})\n",
    "        \n",
    "        \n",
    "        return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = not_null_and_mapping(df_pos, 'POS','hl')\n",
    "df_neg = not_null_and_mapping(df_neg, 'NEG','hl')\n",
    "df_pos_vader = not_null_and_mapping(df_pos_vader, 'POS','vader')\n",
    "df_neg_vader = not_null_and_mapping(df_neg_vader, 'NEG','vader')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning VADER labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compound_score(comment):\n",
    "    ss = sid.polarity_scores(str(comment))\n",
    "    return ss['compound']\n",
    "\n",
    "def get_sentiment(compound_score):\n",
    "    if compound_score > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def vader(df):\n",
    "    for comment in df.COMMENT:\n",
    "        ss = sid.polarity_scores(comment)\n",
    "    \n",
    "    df['compound_score'] = df['COMMENT'].apply(lambda x: get_compound_score(x))\n",
    "    df['PRED_LABEL'] = df['compound_score'].apply(lambda x: get_sentiment(x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_vader = vader(df_pos_vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg_vader = vader(df_neg_vader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining vader labels and true labels on index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pos = pd.merge(df_pos_vader[['COMMENT','PRED_LABEL']], \n",
    "                      df_pos[['TRUE_LABEL']], \n",
    "                      left_index=True, \n",
    "                      right_index=True, \n",
    "                      how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_neg = pd.merge(df_neg_vader[['COMMENT','PRED_LABEL']], \n",
    "                      df_neg[['TRUE_LABEL']], \n",
    "                      left_index=True, \n",
    "                      right_index=True, \n",
    "                      how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating F1 Score for NEU mapped to POS and NEG, respectively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5084140831155031"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_true = result_pos['TRUE_LABEL']\n",
    "y_pred = result_pos['PRED_LABEL']\n",
    "\n",
    "\n",
    "f1_score(y_true, y_pred, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6347994135826863"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_true = result_neg['TRUE_LABEL']\n",
    "y_pred = result_neg['PRED_LABEL']\n",
    "\n",
    "\n",
    "\n",
    "f1_score(y_true, y_pred, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
